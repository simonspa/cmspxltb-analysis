# this file uses emacs Org mode formatting -*- mode: Org; -*-
* Overview
  jobsub is a tool for the convenient run-specific modification of
  Marlin steering files and their execution through the Marlin
  processor.
* Usage
#+begin_example
usage: jobsub.py [-h] [--option NAME=VALUE] [-c FILE] [-csv FILE]
                 [--log-file FILE] [-l LEVEL] [-s] [--dry-run]
                 jobtask [runs [runs ...]]

A tool for the convenient run-specific modification of Marlin steering files
and their execution through the Marlin processor

positional arguments:
  jobtask               Which task to submit (e.g. convert, hitmaker, align);
                        task names are arbitrary and can be set up by the
                        user; they determine e.g. the config section and
                        default steering file names.
  runs                  The runs to be analyzed; can be a list of single runs
                        and/or a range, e.g. 1056-1060. PLEASE NOTE: for
                        technical reasons, the order in which the runs are
                        processed does not necessarily follow the order in
                        which they were specified.

optional arguments:
  -h, --help            show this help message and exit
  --option NAME=VALUE, -o NAME=VALUE
                        Specify further options such as beamenergy=5.3;
                        overrides config file options.
  -c FILE, --conf-file FILE, --config FILE
                        Load specified config file with global and task
                        specific variables
  -csv FILE, --csv-file FILE
                        Load additional run-specific variables from table
                        (text file in csv format)
  --log-file FILE       Save submission log to specified file
  -l LEVEL, --log LEVEL
                        Sets the verbosity of log messages during job
                        submission where LEVEL is either debug, info, warning
                        or error
  -s, --silent          Suppress non-error (stdout) Marlin output to console
  --dry-run             Write steering files but skip actual Marlin execution
#+end_example
* Preparation of Steering File Templates
  Steering file templates are valid Marlin steering files (in xml
  format) where single values are replaced by variables in the form
  "@SomeVariable@".

  When jobsub is run, these placeholders are filled with a
  user-defined value that can be specified through any of these
  sources (in order of precedence): command-line arguments, a config
  file, or a table with a row for each run number processed.
  
  There is only one predefined placeholder, @RunNumber@, which will be
  substituted with the current run number (padded with leading zeros
  to six digits, e.g. 001234).
* Configuration
  There are only very few predefined options: TemplateFile,
  TemplatePath, and LogPath. The former are used to find the correct
  steering file template for the current task while the latter sets
  the path where the final steering file and job output of each run is
  stored (as zip file). The default for the file name is
  "TASK-tmp.xml", where TASK corresponds to the taskname given on the
  command line.  The default path to the template is ".", i.e. the
  current directory.

  You can modify these options is the same way as placeholders in the
  template file, as described below.
** Command Line
   Variable substitutions can be specified using the --option or -o
   command line switches, e.g.

   #+begin_src shell-script
   jobsub.py --option beamenergy=5.3 align 1234
   #+end_src

   Command line options override any options given in the config file.
** Config File
   Config files are text file consisting of sections (indicated by '[]'):
   - a global section called [DEFAULT]
   - task-specific sections

   as well as "name: value" or "name=value" entries, where 'name' are
   arbitrary steering file variables (case-insensitive).

   Some noteworthy features include:
   - comment prefix characters are # and ;
   - interpolation of format strings is supported, for example:
     #+begin_example
     [My Section]
     foodir: %(dir)s/whatever
     dir=frob
     long: this value continues
       in the next line
     #+end_example
     would resolve the %(dir)s to the value of dir (frob in this case).
   - some default interpolations are %(home)s and %(eutelescopePath)s
     which are set up with the environment variables $HOME and
     $EUTELESCOPE, respectively.
   - The string "@RunNumber@" will be replaced in the template *after*
     all other variable strings were filled-in; therefore, you can use
     the @RunNumber@ placeholder inside options, e.g. the file name.
     It will be replaced by the run number padded with leading zeros
     to 6 digits.
   - for more details, see the documentation to the Python module used
     for parsing: http://docs.python.org/2/library/configparser.html

*** Example
    The following is an excerpt from jobsub/examples/datura-alone/config.cfg:
    #+begin_src conf
    [DEFAULT]
    # global section. Settings can be overwritten through task-specific sections
    # the template file name can be set with
    # TemplateFile = file.xml
    # The default is '[task]-tmp.xml'
    BasePath     		= %(eutelescopepath)s/jobsub/examples/datura-alone
    TemplatePath		= %(BasePath)s/steering-templates
    # set the folder which contains the raw/native data files
    NativeFolder            = /afs/desy.de/group/telescopes/EutelTestData/TestExampleDaturaAlone
    # geometry file
    GEARFile    		= gear_desy2012_06f_tb21.xml
    # histogram information
    Histoinfo   		= histoinfo.xml
    # format for the output; @RunNumber@ is the current 
    # run number padded with leading zeros to 6 digits
    Output			= run@RunNumber@
    # which run number to use for hot pixel determination (use current run)
    HotpixelRunNumber	= @RunNumber@
    # do not skip events
    SkipNEvents = 
    # recommended subfolder structure:
    LocalFolderOutputBase	= ./output
    LcioRawFolder            	= %(LocalFolderOutputBase)s/lcio-raw
    DBPath			= %(LocalFolderOutputBase)s/db
    ResultsPath			= %(LocalFolderOutputBase)s/results
    HistoPath			= %(LocalFolderOutputBase)s/histo
    LogPath			= %(LocalFolderOutputBase)s/logs
    # limit processing of run to a certain number of events
    MaxRecordNumber = 100000

    [converter]
    # section for the converter step
    # nothing specific to set here

    [align]
    InputFile		= %(ResultsPath)s/run@RunNumber@-hit.slcio
    PedeSteeringFile	= %(TemplatePath)s/pede-steer-tmp.txt
    # do not need so many events for alignment - this overwrites global value set above
    MaxRecordNumber     = 75000
    ResidualXMin        = -300. -300. -300. -600. -600. -600.
    ResidualXMax        =  300.  300.  300.  600.  600.  600.
    ResidualYMin        = -300. -300. -300. -600. -600. -600.
    ResidualYMax        =  300.  300.  300.  600.  600.  600.
    #+end_src

** Table (comma-separated text file)
   - format: e.g. 
     - export from Open/LibreOffice with default settings (UTF-8,comma-separated, text-field delimiter: ")
     - emacs org-mode table (see http://orgmode.org/manual/Tables.html)
   - commented lines (starting with #) are ignored
   - first row (after comments) has to provide column headers which identify the variables in the steering template to replace (case-insensitive)
   - requires one column labeled "RunNumber"
   - only considers placeholders left in the steering template after processing command-line arguments and config file options
*** Example
    An org-mode emacs table would have the following form:

    #+begin_example
    | RunNumber | BeamEnergy |
    |      4115 |          1 |
    |      4116 |          2 |
    |      4117 |          3 |
    |      4118 |          4 |
    |      4119 |          5 |
    #+end_example

    Using this table, the variable @BeamEnergy@ in the templates would
    be replaced by the value corresponding to the current run number.
* Example
  The following commands show how you would execute the telescope-only
  analysis that is provided as an example:

  First, create the directory structure and set up some environment variables for convenience:

  #+begin_src sh
  export ANALYSIS=/data/testbeam/analysis
  mkdir -p $ANALYSIS/output/histo && mkdir -p $ANALYSIS/output/results \
                    && mkdir -p $ANALYSIS/output/db \
                    && mkdir -p $ANALYSIS/output/logs \
                    && mkdir -p $ANALYSIS/output/lcio-raw
  #+end_src

  The analysis we want to perform is controlled by a config file
  (config.cfg), a csv-table (table_orgmode.csv) and steering file
  templates (*.xml), all located in the examples sub directory of
  jobsub: 
  
  #+begin_src sh
  export ANALYSIS_CONF=$EUTELESCOPE/jobsub/examples/datura-alone
  #+end_src

  In principle, neither the table nor the config are required as long
  as the template files do not contain any variables except for the
  run number ('@RunNumber@').
  
  After making sure that the path to the raw data files in config.cfg
  is correct, we can execute the analysis step-by-step:

  First, converter step:
  #+begin_src sh
  cd $ANALYSIS
  $EUTELESCOPE/jobsub/jobsub.py --config=${ANALYSIS_CONF}/config.cfg \
                   -csv ${ANALYSIS_CONF}/table_orgmode.csv converter 4118
  #+end_src

  Here, jobsub will generate a steering file using the template file
  specified in the config file (default would be 'converter-tmp.xml'),
  thereby replacing any variables given in the config and table files.
  The final steering file will be processed by executing Marlin.
  
  The next steps follow the same pattern:
  #+begin_src sh
  $EUTELESCOPE/jobsub/jobsub.py --config=${ANALYSIS_CONF}/config.cfg \
                    -csv ${ANALYSIS_CONF}/table_orgmode.csv clusearch 4118
  $EUTELESCOPE/jobsub/jobsub.py --config=${ANALYSIS_CONF}/config.cfg \
                    -csv ${ANALYSIS_CONF}/table_orgmode.csv hitmaker 4118
  $EUTELESCOPE/jobsub/jobsub.py --config=${ANALYSIS_CONF}/config.cfg \
                    -csv ${ANALYSIS_CONF}/table_orgmode.csv align 4118
  $EUTELESCOPE/jobsub/jobsub.py --config=${ANALYSIS_CONF}/config.cfg 
                    -csv ${ANALYSIS_CONF}/table_orgmode.csv fitter 4118
  #+end_src sh

  For this example, the output of each step is stored in
  sub directories of the $ANALYSIS path. This is configurable through
  the paths in the config.cfg file.

  If all steps succeed, we end up with an LCIO-Collection of tracks on
  which detailed studies can be performed.
    
* Appendix 1: pysub migration
  Currently, jobsub does not directly support submission on the grid;
  if you need this functionality, please stay with pysub for now.

  *Please consider setting up a template from scratch*: this will ensure
  that all existing settings are present and show the correct defaults
  and that the documenting comments are up-to-date. Furthermore, the
  resulting steering file and jobsub configuration will be much simpler
  than their pysub counterparts.

  If you still want to keep the steering files used previously with
  pysub, you can manually convert them. You mainly need to modify the
  configuration files: (replace all bold names with your settings)

  - Set up the global settings section "[Default]"

  - Set up sections for each of your analysis tasks, e.g.    
    #+begin_example
    [align]
    [converter]
    [hitmaker]
    [fitter]
    #+end_example
    or rename existing sections such as [AlignOptions] to the
    corresponding task name.

  - Move task-specific options to the corresponding section

  - if your steering files do not follow the naming convention
    NAME-tmp.xml you need to have the setting
    #+begin_example
    TemplateFile = YOUR_FILE_NAME.xml
    #+end_example
    in each task section.
    Add the setting
    #+begin_example
    src_conf{TemplatePath = (RELATIVE)_PATH_TO_YOUR_TEMPLATES}
    #+end_example
    to the global section (or task sections if it varies 
    for each task)

  - delete obsolete sections: "[SteeringTemplate]"

  - Move any non-task specific sections into the global [default]
    section: this applies e.g. to [General], [Logger] and [LOCAL] options

  - Rename the "LocalFolder..." options:
    #+begin_example
    LocalFolderNative -> NativeFolder
    LocalFolderGear -> GearPath
    LocalFolderLcioRaw -> LcioRawPath
    LocalFolderHistoInfo -> HistoInfoPath
    LocalFolderTASKNAMEJoboutput -> LogPath
    LocalFolderTASKNAMEHisto -> HistoPath (either globally or in local sections)
    LocalFolderDBTASKNAME -> DBPath (again, either globally or locally)
    LocalFolderTASKNAMEResults -> ResultsPath (globally or locally)
    #+end_example

  - Set the following options: 
    Globally:
    #+begin_example
    Output = @RunNumber@
    #+end_example
    In each task section, modify accordingly:
    e.g. in [align]:
    #+begin_example
    InputFile = %(ResultsPath)s/hit-@RunNumber@.slcio
    #+end_example
    
  - Run jobsub; if it complains about "Missing configuration
    parameters", check your template and config for any of the listed
    parameters and set their value in the config or remove them from
    the steering file.
   
